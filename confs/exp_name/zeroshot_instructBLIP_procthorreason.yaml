exp_name: zeroshot_instructBLIP_procthorreason
device: 'gpu'
num_workers: 4

### loading checkpoints, eval, train options
num_epochs: 50
batch_size: 1
lr: 0.000005
weight_decay: 0.000001
lr_scheduler: "cosine"
eval_only: True # if this is set to True, only the val dataset will be run.
tune_lora: False
load_checkpoint: False

lora_model_path: False 

eval_every: 5000

num_eval_steps: 2000
no_shuffle: False

freeze_vision: False

## define your val dataset, the name must match the class name in datasets/dataloaders.py. This is run only when eval_only is set to True

val_dataset_choice: "ProcTHOR_reasoning"
val_dataset_args: {
  split: "val",
  mode: "val",
  prompt_mode: "zero_shot",
  instructBLIP: True,
}
val_collate_fn: "collate_fn" 


## define model. The name must match the class name in models/model_interface.py
model_choice: "InstructBlipModelInterface"
model_init_args: {
}
# the model must output a huggingface output in its forward function.

# These are the inputs to the model. These variables must be present in the dictionary output from your dataloader in datasets/dataloaders.py.
model_input_choice: ['input_ids', 'qformer_input_ids', 'attention_mask', 'qformer_attention_mask', 'pixel_values', 'labels']

## Metrics [name, torchmetric_class_name_in_eval.py, metric init args, metric update args]:
metrics: [ 
  ['ReasoningAccuracy', 'ReasoningAccuracy', [], []],
]
